{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lesions = {0: \"Basal Cell Carcinoma\", \n",
    "    1: \"Lentigo\",\n",
    "    2: \"Malignant Melanoma\", \n",
    "    3: \"Melanocytic naevus\",\n",
    "    4: \"seborrhoeic keratosis\",\n",
    "    5: \"Wart\", \n",
    "    6: \"Actinic Keratosis\",\n",
    "    7: \"Squamous Cell Carcinoma\",\n",
    "    8: \"Intraepithelial Carcinoma\", \n",
    "    9: \"Pyogenic Granuloma\",\n",
    "    10: \"Haemangioma\",\n",
    "    11: \"Dermatofibroma\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                  id  label\n",
       "0  dataset-split/train/Wart/Wart_original_100.jpg...      5\n",
       "1  dataset-split/train/Wart/Wart_original_37.jpg_...      5\n",
       "2  dataset-split/train/Wart/Wart_original_2.jpg_4...      5\n",
       "3  dataset-split/train/Wart/Wart_original_21.jpg_...      5\n",
       "4  dataset-split/train/Wart/Wart_original_54.jpg_...      5"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>dataset-split/train/Wart/Wart_original_100.jpg...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dataset-split/train/Wart/Wart_original_37.jpg_...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>dataset-split/train/Wart/Wart_original_2.jpg_4...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>dataset-split/train/Wart/Wart_original_21.jpg_...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>dataset-split/train/Wart/Wart_original_54.jpg_...</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv',index_col=0)\n",
    "test = pd.read_csv('test.csv',index_col=0)\n",
    "val = pd.read_csv('val.csv',index_col=0)\n",
    "\n",
    "train_y = train['label'].values\n",
    "test_y = test['label'].values\n",
    "val_y = val['label'].values\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(train)\n",
    "df_test = pd.DataFrame(test)\n",
    "df_val = pd.DataFrame(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1\n",
    "train_dataset_filenames = df_train['id'].values.tolist()\n",
    "train_dataset_labels = df_train['label'].values.tolist()\n",
    "filenames = tf.constant(train_dataset_filenames)\n",
    "labels = tf.constant(train_dataset_labels)\n",
    "\n",
    "# step 2: create a dataset returning slices of `filenames`\n",
    "dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "\n",
    "# step 3: parse every image in the dataset using `map`\n",
    "def _parse_function(filename, label):\n",
    "    image_string = tf.io.read_file(filename)\n",
    "    image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n",
    "    image = tf.cast(image_decoded, tf.float32)\n",
    "    return image, label\n",
    "\n",
    "dataset = dataset.map(_parse_function)\n",
    "dataset = dataset.batch(2)\n",
    "\n",
    "# step 4: create iterator and final input tensor\n",
    "iterator = tf.compat.v1.data.make_one_shot_iterator(dataset)\n",
    "images, labels = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}