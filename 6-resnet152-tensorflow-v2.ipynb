{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1.keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import imshow, legend, show, figure\n",
    "from keras_lr_finder import LRFinder  \n",
    "\n",
    "print(tf.version.VERSION)\n",
    "# tf.compat.v1.disable_v2_behavior()\n",
    "# tf.compat.v1.disable_eager_execution()\n",
    "tf.compat.v1.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lesions = {0: \"Basal Cell Carcinoma\", \n",
    "    1: \"Lentigo\",\n",
    "    2: \"Malignant Melanoma\", \n",
    "    3: \"Melanocytic naevus\",\n",
    "    4: \"seborrhoeic keratosis\",\n",
    "    5: \"Wart\", \n",
    "    6: \"Actinic Keratosis\",\n",
    "    7: \"Squamous Cell Carcinoma\",\n",
    "    8: \"Intraepithelial Carcinoma\", \n",
    "    9: \"Pyogenic Granuloma\",\n",
    "    10: \"Haemangioma\",\n",
    "    11: \"Dermatofibroma\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 53820 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 22\n",
    "\n",
    "src_path_train = \"dataset-split/train/\"\n",
    "def my_preprocessing_func(img):\n",
    "    image = np.array(img)\n",
    "#     image = image / .8\n",
    "    image = tf.keras.applications.resnet_v2.preprocess_input(image)\n",
    "    return image\n",
    "\n",
    "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=my_preprocessing_func).flow_from_directory(\n",
    "    directory=src_path_train,\n",
    "    subset='training',\n",
    "    class_mode=\"sparse\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    target_size=(224, 224),\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6570 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "src_path_val = \"dataset-split/val/\"\n",
    "val_generator = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=my_preprocessing_func).flow_from_directory(\n",
    "    directory=src_path_val,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"sparse\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plots(ims, figsize=(14,6), rows=3, interp=False, titles='lesions'):\n",
    "#     if type(ims[0]) is np.ndarray:\n",
    "#         ims = np.array(ims)\n",
    "#         if (ims.shape[-1] != 3):\n",
    "#             ims = ims.transpose((0,2,3,1))\n",
    "#     f = figure(figsize=figsize)\n",
    "#     cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n",
    "#     for i in range(len(ims)):\n",
    "#         sp = f.add_subplot(rows, cols, i+1)\n",
    "#         sp.axis('Off')\n",
    "#         if titles is not None:\n",
    "#             sp.set_title(titles[i], fontsize=16)\n",
    "#         imshow(ims[i], interpolation=None if interp else 'none')\n",
    "        \n",
    "# imgs, labels = next(train_generator)\n",
    "\n",
    "# plots(imgs, titles=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src_path_test = \"dataset-split/test/\"\n",
    "# test_generator = tf.keras.preprocessing.image.ImageDataGenerator().flow_from_directory(\n",
    "#     directory=src_path_test,\n",
    "#     target_size=(224, 224),\n",
    "#     color_mode=\"rgb\",\n",
    "#     batch_size=1,\n",
    "#     class_mode=None,\n",
    "#     shuffle=False,\n",
    "#     seed=42\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imshow(tf.cast(images_val[5], tf.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2447/2447 [==============================] - ETA: 0s - batch: 1223.0000 - size: 21.9943 - loss: 4.9659 - acc: 0.3103 - sparse_top_k_categorical_accuracy: 0.7378 - Multilabel_confusion_matrix: 22449.9375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2447/2447 [==============================] - 1371s 554ms/step - batch: 1223.0000 - size: 21.9943 - loss: 4.9659 - acc: 0.3103 - sparse_top_k_categorical_accuracy: 0.7378 - Multilabel_confusion_matrix: 22449.9375 - val_loss: 4.3522 - val_acc: 0.3151 - val_sparse_top_k_categorical_accuracy: 0.7416 - val_Multilabel_confusion_matrix: 2739.3958\n",
      "Epoch 2/10\n",
      "2447/2447 [==============================] - 1316s 538ms/step - batch: 1223.0000 - size: 21.9943 - loss: 4.4879 - acc: 0.3099 - sparse_top_k_categorical_accuracy: 0.7162 - Multilabel_confusion_matrix: 22496.0000 - val_loss: 4.2937 - val_acc: 0.3151 - val_sparse_top_k_categorical_accuracy: 0.7215 - val_Multilabel_confusion_matrix: 2740.5833\n",
      "Epoch 3/10\n",
      "2447/2447 [==============================] - 1304s 533ms/step - batch: 1223.0000 - size: 21.9943 - loss: 4.4831 - acc: 0.3099 - sparse_top_k_categorical_accuracy: 0.7115 - Multilabel_confusion_matrix: 22496.8535 - val_loss: 4.2968 - val_acc: 0.3151 - val_sparse_top_k_categorical_accuracy: 0.7260 - val_Multilabel_confusion_matrix: 2740.0000\n",
      "Epoch 4/10\n",
      "2447/2447 [==============================] - 1311s 536ms/step - batch: 1223.0000 - size: 21.9943 - loss: 4.4694 - acc: 0.3099 - sparse_top_k_categorical_accuracy: 0.7123 - Multilabel_confusion_matrix: 22496.9785 - val_loss: 4.1962 - val_acc: 0.3151 - val_sparse_top_k_categorical_accuracy: 0.7207 - val_Multilabel_confusion_matrix: 2740.3125\n",
      "Epoch 5/10\n",
      "2447/2447 [==============================] - 1313s 536ms/step - batch: 1223.0000 - size: 21.9943 - loss: 4.3683 - acc: 0.3099 - sparse_top_k_categorical_accuracy: 0.7114 - Multilabel_confusion_matrix: 22497.1875 - val_loss: 4.1955 - val_acc: 0.3151 - val_sparse_top_k_categorical_accuracy: 0.7210 - val_Multilabel_confusion_matrix: 2740.3125\n",
      "Epoch 6/10\n",
      "2447/2447 [==============================] - 1304s 533ms/step - batch: 1223.0000 - size: 21.9943 - loss: 4.3605 - acc: 0.3099 - sparse_top_k_categorical_accuracy: 0.7116 - Multilabel_confusion_matrix: 22497.5215 - val_loss: 4.1957 - val_acc: 0.3151 - val_sparse_top_k_categorical_accuracy: 0.7186 - val_Multilabel_confusion_matrix: 2740.4792\n",
      "Epoch 7/10\n",
      "2447/2447 [==============================] - 1333s 545ms/step - batch: 1223.0000 - size: 21.9943 - loss: 4.3592 - acc: 0.3099 - sparse_top_k_categorical_accuracy: 0.7114 - Multilabel_confusion_matrix: 22497.4375 - val_loss: 4.1951 - val_acc: 0.3151 - val_sparse_top_k_categorical_accuracy: 0.7195 - val_Multilabel_confusion_matrix: 2740.4167\n",
      "Epoch 8/10\n",
      "1459/2447 [================>.............] - ETA: 8:39 - batch: 729.0000 - size: 21.9904 - loss: 4.3593 - acc: 0.3118 - sparse_top_k_categorical_accuracy: 0.7101 - Multilabel_confusion_matrix: 13391.5205"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-91621e8c05e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m history = model.fit(train_generator,\n\u001b[1;32m     42\u001b[0m                     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                     epochs=epochs)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator_v1.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1086\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3956\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3957\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3958\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3959\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1480\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1481\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1483\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "lr = 0.0003\n",
    "eps = 10e-3\n",
    "epochs = 10\n",
    "momentum = 0.9\n",
    "wd = 1e-05\n",
    "gamma = 0.1\n",
    "ds = train_generator.samples / BATCH_SIZE\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.applications.ResNet152V2(input_shape=(224,224,3), weights='imagenet', include_top=False))\n",
    "model.add(tf.keras.layers.GlobalAveragePooling2D(name='avg_pool'))\n",
    "model.add(tf.keras.layers.Dense(12, activation=tfa.activations.sparsemax, name='predictions'))\n",
    "\n",
    "# model.add(tf.keras.layers.AveragePooling2D((7, 7), name='avg_pool'))\n",
    "# model.add(tf.keras.layers.Flatten())\n",
    "# model.add(tf.keras.layers.Dense(12, activation='softmax', name='predictions'))\n",
    "\n",
    "# lr_scheduling = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "#     initial_learning_rate=lr, decay_steps=ds, decay_rate=dr\n",
    "# )\n",
    "\n",
    "lr_scheduling = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=lr, decay_steps=ds, decay_rate=gamma, staircase=True\n",
    ")\n",
    "\n",
    "\n",
    "# opt = tf.keras.optimizers.Adam(learning_rate=lr, epsilon=eps)\n",
    "opt = tfa.optimizers.SGDW(learning_rate=lr_scheduling, momentum=momentum, weight_decay=wd)\n",
    "\n",
    "# loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "#     y_true= , y_pred, from_logits=False, axis=-1\n",
    "# )\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy', 'sparse_top_k_categorical_accuracy', tfa.metrics.MultiLabelConfusionMatrix(num_classes=12)])\n",
    "\n",
    "history = model.fit(train_generator,\n",
    "                    validation_data = val_generator,\n",
    "                    epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('model/tensorflow-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_weights('model/tensorflow-model-weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import shap\n",
    "except Exception as error:\n",
    "    !pip install {str(error)[17:-1]}\n",
    "    import shap\n",
    "except:\n",
    "    print(\"Pacote n√£o encontrado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.shape[0])\n",
    "\n",
    "background = x[np.random.choice(x.shape[0], 2)]\n",
    "\n",
    "# explain predictions of the model on four images\n",
    "e = shap.DeepExplainer(model, background)\n",
    "# ...or pass tensors directly\n",
    "# e = shap.DeepExplainer((model.layers[0].input, model.layers[-1].output), background)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = e.shap_values(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the feature attributions\n",
    "shap.image_plot(shap_values, -x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model/tensorflow-model-low-test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('model/tensorflow-model-low-test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "import pandas as pd\n",
    "import random\n",
    "test = pd.read_csv('test.csv',index_col=0)\n",
    "train = pd.read_csv('train.csv',index_col=0)\n",
    "df_test = pd.DataFrame(test)\n",
    "test_dataset_filenames = df_test['id'].values.tolist()\n",
    "test_dataset_filenames_background = np.random.choice(test_dataset_filenames, 10, replace=False)\n",
    "test_dataset_filenames = np.random.choice(test_dataset_filenames, 5, replace=False)\n",
    "\n",
    "numpy_images = []\n",
    "for image in test_dataset_filenames:\n",
    "    image = Image.open(\"../input/datasetsplit/\" + image)\n",
    "    image = asarray(image)\n",
    "    image = tf.keras.applications.resnet_v2.preprocess_input(image)\n",
    "    numpy_images.append(image)\n",
    "    \n",
    "background = []\n",
    "for image in test_dataset_filenames_background:\n",
    "    image = Image.open(\"../input/datasetsplit/\" + image)\n",
    "    image = asarray(image)\n",
    "    image = image.astype(np.float32)\n",
    "    image /= 255\n",
    "    background.append(image)\n",
    "    \n",
    "x_pixel_values = []\n",
    "for image in test_dataset_filenames:\n",
    "    image = Image.open(\"../input/datasetsplit/\" + image)\n",
    "    image = asarray(image)\n",
    "    image = image.astype(np.float32)\n",
    "    image /= 255\n",
    "    x_pixel_values.append(image)\n",
    "\n",
    "background = asarray(background)\n",
    "x = asarray(numpy_images)\n",
    "x_pixel_values = asarray(x_pixel_values)\n",
    "imshow(x_pixel_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.shape[0])\n",
    "\n",
    "# explain predictions of the model on four images\n",
    "e = shap.DeepExplainer(new_model, background)\n",
    "# ...or pass tensors directly\n",
    "# e = shap.DeepExplainer((model.layers[0].input, model.layers[-1].output), background)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = e.shap_values(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.image_plot(shap_values, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
